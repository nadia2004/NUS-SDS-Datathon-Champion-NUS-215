{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
    "##### Ensure that the proper library names are used and the syntax of `%pip install PACKAGE_NAME` is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas \n",
    "%pip install matplotlib\n",
    "# add commented pip installation lines for packages used as shown above for ease of testing\n",
    "# the line should be of the format %pip install PACKAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DO NOT CHANGE** the filepath variable\n",
    "##### Instead, create a folder named 'data' in your current working directory and \n",
    "##### have the .csv file inside that. A relative path *must* be used when loading data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can have as many cells as you want for code\n",
    "import pandas as pd\n",
    "filepath = \"./data/catA_train.csv\" \n",
    "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ALL** Code for machine learning and dataset analysis should be entered below. \n",
    "##### Ensure that your code is clear and readable.\n",
    "##### Comments and Markdown notes are advised to direct attention to pieces of code you deem useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "\n",
    "df2 = pd.read_csv('/content/drive/MyDrive/catA_train.csv')\n",
    "\n",
    "# get information about our dataframe\n",
    "print(df2.info())\n",
    "\n",
    "# find the number of rows and columns in our dataset\n",
    "print(df2.shape)\n",
    "\n",
    "# find the names of columns in our dataset\n",
    "print(df2.columns)\n",
    "\n",
    "# check for the number of missing values in the dataframe\n",
    "df2.isna().sum()\n",
    "\n",
    "# show count, mean, std, and quintile information for each numerical column\n",
    "df2.describe()\n",
    "\n",
    "# a look at the first few rows of our data\n",
    "df2.head(5)\n",
    "\n",
    "# removes rows without either lat or long coordinates\n",
    "df2 = df2.dropna(subset=[\"LATITUDE\", \"LONGITUDE\"])\n",
    "df2.drop('Square Footage', axis=1, inplace=True)\n",
    "df2.drop('Import/Export Status', axis=1, inplace=True)\n",
    "df2.drop('Fiscal Year End', axis=1, inplace=True)\n",
    "df2.head(5)\n",
    "\n",
    "# Remove rows where the Company Status is 'Inactive'\n",
    "df2 = df2[df2['Company Status (Active/Inactive)'] == 'Active']\n",
    "\n",
    "# to ensure important info isnt being lost\n",
    "#df2['Import/Export Status_Missing'] = df2['Import/Export Status'].isna()\n",
    "\n",
    "df3 = df2.dropna(subset=[\"Employees (Single Site)\", \"Employees (Domestic Ultimate Total)\", \"Employees (Global Ultimate Total)\",\n",
    "                                       \"Year Found\"])\n",
    "\n",
    "df3 = pd.get_dummies(df2, columns=['Entity Type'], prefix='Entity_Type')\n",
    "df3 = pd.get_dummies(df2, columns=['Ownership Type'], prefix='Ownership_Type')\n",
    "#df3 = pd.get_dummies(df2, columns=['Import/Export Status'], prefix='Import_Export_Status')\n",
    "df3 = df2.drop(columns=[col for col in [\"Company Status (Active/Inactive)\", \"Entity Type\", 'Import/Export Status', 'Ownership Type'] if col in df2.columns], errors='ignore') # are all Active\n",
    "\n",
    "# Check the number of null values\n",
    "df3.isna().sum()\n",
    "\n",
    "# Find the frequency of each industry\n",
    "sic_code_frequency = df3['SIC Code'].value_counts()\n",
    "\n",
    "# Set a threshold for low-frequency SIC Codes\n",
    "threshold = 7  # Adjust this threshold based on your preference\n",
    "\n",
    "# Identify SIC Codes with frequency below the threshold\n",
    "low_frequency_sic_codes = sic_code_frequency[sic_code_frequency < threshold].index\n",
    "\n",
    "# Replace these low-frequency SIC Codes with a common label \"Others\"\n",
    "df3['SIC Code'] = df3['SIC Code'].replace(low_frequency_sic_codes, 'Others')\n",
    "\n",
    "sic_code_frequency1 = df3['SIC Code'].value_counts()\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(sic_code_frequency1)\n",
    "\n",
    "# convert to str cus we dont want it to be trained as a numeric value\n",
    "# Convert the entire column to a common data type (string in this case)\n",
    "df3['SIC Code'] = df3['SIC Code'].astype(str)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Use label encoding for 'SIC Code'\n",
    "label_encoder = LabelEncoder()\n",
    "df3['SIC Code'] = label_encoder.fit_transform(df3['SIC Code'])\n",
    "\n",
    "df3[\"SIC Code\"].unique()\n",
    "\n",
    "# use of a correlation matrix to observe how variables in our dataset may be affected by others\n",
    "numerical_df = df3.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Create a correlation matrix\n",
    "correlation_matrix = numerical_df.corr()\n",
    "\n",
    "# Assuming correlation_matrix is your correlation matrix\n",
    "correlation_df = pd.DataFrame(correlation_matrix)\n",
    "\n",
    "# Print or use the correlation DataFrame as needed\n",
    "correlation_df\n",
    "\n",
    "# import required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# we will need this for the color gradient representing how high the domestic sales figure is.\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "\n",
    "# for the upcoming geospatial analysis portion, we will use a small subset of the data provided for plotting.\n",
    "filtered_df = df2[df2['SIC Code'].isin([5099, 1611, 8711, 4789])]\n",
    "\n",
    "filtered_df.head(2)\n",
    "\n",
    "# read in the filtered dataset and do EDA. confusion matrix, etc\n",
    "# Use LogNorm for more sensitivity to numerical changes\n",
    "norm = LogNorm()\n",
    "\n",
    "# Define a constant color (e.g., blue)\n",
    "constant_color = 'blue'\n",
    "\n",
    "# Define a color palette based on unique industries\n",
    "industry_palette = sns.color_palette('Set1', n_colors=len(filtered_df['Industry'].unique()))\n",
    "\n",
    "# Create a dictionary to map Industry to a unique color\n",
    "industry_colors = dict(zip(filtered_df['Industry'].unique(), industry_palette))\n",
    "\n",
    "# Scatter plot with varying color by Industry and varying alpha based on Sales values\n",
    "scatter = plt.scatter(filtered_df['LONGITUDE'], filtered_df['LATITUDE'], c=filtered_df['Industry'].map(industry_colors), s=3, alpha=norm(filtered_df['Sales (Domestic Ultimate Total USD)']))\n",
    "\n",
    "# Add a legend for Industry\n",
    "legend_labels = filtered_df['Industry'].unique()\n",
    "legend_handles = [plt.Line2D([0], [0], marker='o', color='w', label=industry,\n",
    "                              markerfacecolor=industry_colors[industry], markersize=4) for industry in legend_labels]\n",
    "plt.legend(handles=legend_handles, title='Industry', prop={'size': 5}, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Scatter Plot with Varying Color by Industry and Varying Alpha Based on Sales (LogNorm)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Use LogNorm for more sensitivity to numerical changes\n",
    "norm = LogNorm()\n",
    "\n",
    "# Define a colormap transitioning from blue to red\n",
    "cmap = 'plasma'\n",
    "\n",
    "# Scatter plot with colors based on Sales values and LogNorm\n",
    "scatter = plt.scatter(filtered_df['LONGITUDE'], filtered_df['LATITUDE'], c=filtered_df['Sales (Domestic Ultimate Total USD)'], cmap=cmap, s=5, norm=norm)\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = plt.colorbar(scatter, label='Sales')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Scatter Plot with Colors Based on Sales (LogNorm)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Specify columns to drop\n",
    "columns_to_drop = [\"error\", \"Fiscal Year End\", \"Sales (Global Ultimate Total USD)\", \"Global Ultimate Company\", \"Domestic Ultimate Company\", \"Web Address\",\n",
    "                   \"Sales (Global Ultimate Total USD)\", \"Square Footage\", \"Company Description\", \"PostCode\", \"8-Digit SIC Code\", \"8-Digit SIC Description\", \"AccountID\",\n",
    "                   \"Parent Company\", \"City\", \"Country\", \"Address\", \"Address1\", \"Industry\", \"Region\", \"Parent Country\", \"Global Ultimate Country\", \"Company\", \"LATITUDE\", \"LONGITUDE\"]\n",
    "\n",
    "# Drop columns if they exist in the DataFrame\n",
    "df4 = df3.drop(columns=[col for col in columns_to_drop if col in df3.columns], errors='ignore')\n",
    "\n",
    "df4 = df4.dropna(subset=[\"Employees (Single Site)\", \"Employees (Domestic Ultimate Total)\", \"Employees (Global Ultimate Total)\",\n",
    "                                       \"Year Found\"])\n",
    "\n",
    "<ipython-input-25-c1976c9a3026>:2: SettingWithCopyWarning: \n",
    "A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "Try using .loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "  df4['Is Domestic Ultimate'] = df4['Is Domestic Ultimate'] == 1\n",
    "<ipython-input-25-c1976c9a3026>:3: SettingWithCopyWarning: \n",
    "A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "Try using .loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "  df4['Is Global Ultimate'] = df4['Is Global Ultimate'] == 1\n",
    "\n",
    "Index(['SIC Code', 'Year Found', 'Employees (Single Site)',\n",
    "       'Employees (Domestic Ultimate Total)',\n",
    "       'Employees (Global Ultimate Total)',\n",
    "       'Sales (Domestic Ultimate Total USD)', 'Is Domestic Ultimate',\n",
    "       'Is Global Ultimate'],\n",
    "      dtype='object')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell below is **NOT** to be removed\n",
    "##### The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list). \n",
    "##### It is recommended to test the function out prior to submission\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "##### The hidden_data parsed into the function below will have the same layout columns wise as the dataset *SENT* to you\n",
    "##### Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_hidden_data(hidden_data: pd.DataFrame) -> list:\n",
    "    '''DO NOT REMOVE THIS FUNCTION.\n",
    "\n",
    "The function accepts a dataframe as input and return an iterable (list)\n",
    "of binary classes as output.\n",
    "\n",
    "The function should be coded to test on hidden data\n",
    "and should include any preprocessing functions needed for your model to perform. \n",
    "    \n",
    "All relevant code MUST be included in this function.'''\n",
    "\n",
    "    \n",
    "    df4 = pd.DataFrame\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    \n",
    "    # Assuming df is your DataFrame with a binary target variable 'target' and features\n",
    "    # X is the feature matrix, and y is the target variable\n",
    "    X = df4.drop('Sales (Domestic Ultimate Total USD)', axis=1)\n",
    "    y = df4['Sales (Domestic Ultimate Total USD)']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create a Decision Tree model\n",
    "    dt_regressor = DecisionTreeRegressor()\n",
    "    \n",
    "    # Train the model\n",
    "    dt_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = dt_regressor.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'R-squared: {r2}')\n",
    "    result = \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell to check testing_hidden_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should output a list of predictions.\n",
    "test_df = pd.read_csv(filepath)\n",
    "test_df = test_df.drop(columns=['Sales (Domestic Ultimate Total USD)'])\n",
    "print(testing_hidden_data(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please have the filename renamed and ensure that it can be run with the requirements above being met. All the best!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
